# can Json rpc give me erc20 and nft info?

    do test nets have them as well?
# am I doing eth1 spec or eth1+ or current eth spec? like london shanghai merge ect? multi version

#eth.sendTransaction({from:eth.accounts[0],to:"0x18d65fb8d60c1199bb1ad381be47aa692b482605",value:1000,gasPrice:82000000000})
Error: block not found
        at web3.js:6357:37(47)
        at web3.js:5091:62(37)
        at <eval>:1:20(15)
geth js console
https://discord.com/channels/482467812179181568/482467812816977921/865083601908662303
# so how are the tests going to built in the future?

# should I do someting similar to [JSON RPC spec](https://www.jsonrpc.org/specification)?

    1 does 


I need to see how pending transactions

So I didn't fall asleep until 4 on tuesday so yesterday I started around 6 Wednsday But I have been doing things untill now

I spent about 5 hours on a personal project that I needed to flesh out while the idea was still fresh.

Then 6 hours doing research for this project I think I have what will become the final product.
Since the core devs are too busy to look at a pr for 15 minutes I agree with just doing it ourselvs 
I have been looking into how I can improve data collection 
I will be slowly inplementing docker and a few other softwares to rapidly improve data collection
I think I should be able to add to it overtime to get a vlauabvle tool
I am just going to start with geth --http --dev in docker which should take aprox 40 minutes
If it takes longer I will drop it, if it goes faster I will add infura, etherscan, linux and windows ect. if things are working 1.5 Hours max time spent 
I found the JSON RPC spec and I want to use a similar format for our spec, I will be spending 4 hours on it 
https://www.jsonrpc.org/specification
I will use it for eth_call and a few other once I get the template out I think I can get a good ammount of drafts done
I will collect data for 3+ endpoints which should take about 4 hours
I will probably start with a contrtact to deploy on solididy to get some data for eth_compileSolidy 
then deploy contrtact on different networks but start with one then get the block filters data compleatly document
with drafts mentioned above

I am also wondering what I am collecting? am I doing eth1 spec JSON RPC or am I doing like what will be the running eth spec sheet for shanghai, and merge/post merge? because this will help determine how I want to structure this going forward.

I also got my first two paycheks yesterday so that was nice. 

I probably could tell more but I am falling asleep at my desk
but yesterdays learning will make todays progress easier. 
I am at aproimately the same position % wise with everything, I worked on a few drafts and data collection
I did more learning and refining the process and vision for the end product
I will be back on in 8 ish hours